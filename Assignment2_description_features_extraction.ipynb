{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import urllib\n",
    "import googlemaps\n",
    "import json\n",
    "import time, datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "import string\n",
    "from string import punctuation\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "panda_data = pandas.read_json('../train.json')\n",
    "panda_test_data = pandas.read_json('test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('records.json', 'w') as outfile:\n",
    "    json.dump(json.loads(panda_data.to_json(orient='records')), outfile)\n",
    "    \n",
    "with open('records_test.json', 'w') as outfile:\n",
    "    json.dump(json.loads(panda_test_data.to_json(orient='records')), outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parseData(fname):\n",
    "    for l in urllib.urlopen(fname):\n",
    "        yield eval(l)\n",
    "        \n",
    "data = np.transpose(list(parseData('records.json')))\n",
    "test_data = np.transpose(list(parseData('records_test.json')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . display_address : Metropolitan Avenue\n",
      "2 . description : A Brand New 3 Bedroom 1.5 bath ApartmentEnjoy These Following Apartment Features As You Rent Here? Modern Designed Bathroom w/ a Deep Spa Soaking Tub? Room to Room AC/Heat? Real Oak Hardwood Floors? Rain Forest Shower Head? SS steel Appliances w/ Chef Gas Cook Oven & LG Fridge? washer /dryer in the apt? Cable Internet Ready? Granite Counter Top Kitchen w/ lot of cabinet storage spaceIt's Just A Few blocks To L Train<br /><br />Don't miss out!<br /><br />We have several great apartments in the immediate area.<br /><br />For additional information 687-878-2229<p><a  website_redacted \n",
      "3 . price : 3000\n",
      "4 . bedrooms : 3\n",
      "5 . photos : ['https://photos.renthop.com/2/7211212_1ed4542ec81621d70d1061aa833e669c.jpg', 'https://photos.renthop.com/2/7211212_7dfc41dced69245065df83d08eed4a00.jpg', 'https://photos.renthop.com/2/7211212_c17853c4b869af6f53af08b0f5820b4c.jpg', 'https://photos.renthop.com/2/7211212_787ad8ea0c089792e7453e2121f8ac89.jpg', 'https://photos.renthop.com/2/7211212_2e88b0d293ee333c804c2f00536eee49.jpg']\n",
      "6 . bathrooms : 1.5\n",
      "7 . features : []\n",
      "8 . listing_id : 7211212\n",
      "9 . building_id : 53a5b119ba8f7b61d4e010512e0dfc85\n",
      "10 . created : 2016-06-24 07:54:24\n",
      "11 . longitude : -73.9425\n",
      "12 . manager_id : 5ba989232d0489da1b5f2c45f6688adc\n",
      "13 . latitude : 40.7145\n",
      "14 . interest_level : medium\n",
      "15 . street_address : 792 Metropolitan Avenue\n"
     ]
    }
   ],
   "source": [
    "for i, k in enumerate(data[0][0]):\n",
    "    print i+1, '.', k, ':', data[0][0][k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Saransh/anaconda/envs/tensorflow_env/lib/python2.7/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html5lib\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 174 of the file /Users/Saransh/anaconda/envs/tensorflow_env/lib/python2.7/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"html5lib\")\n",
      "\n",
      "  markup_type=markup_type))\n",
      "/Users/Saransh/anaconda/envs/tensorflow_env/lib/python2.7/site-packages/bs4/__init__.py:219: UserWarning: \".\" looks like a filename, not markup. You shouldprobably open this file and pass the filehandle intoBeautiful Soup.\n",
      "  'Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Training\n"
     ]
    }
   ],
   "source": [
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text, stemmer=PorterStemmer()):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize, stop_words='english')\n",
    "\n",
    "def trainTfIdfModel(strings):\n",
    "    content = np.array([])\n",
    "    tfIdfScores = np.array([])\n",
    "    print 'Preprocessing Data'\n",
    "    for s in strings:\n",
    "        t = \" \".join(item.strip() for item in BeautifulSoup(s).find_all(text=True))\n",
    "        t = str(''.join([i if ord(i) < 128 else ' ' for i in t]))\n",
    "        replace_punctuation = string.maketrans(punctuation, ' '*len(punctuation))\n",
    "        transformed_string = t.lower().translate(replace_punctuation)\n",
    "        content = np.append(content, transformed_string)\n",
    "     \n",
    "    print 'Started Training'\n",
    "    tfs = tfidf.fit_transform(content)\n",
    "\n",
    "trainTfIdfModel([d[0]['description'] for d in data])\n",
    "\n",
    "def getTransformedtfIdfScore(review):\n",
    "    t = \" \".join(item.strip() for item in BeautifulSoup(review).find_all(text=True))\n",
    "    t = str(''.join([i if ord(i) < 128 else ' ' for i in t]))\n",
    "    replace_punctuation = string.maketrans(punctuation, ' '*len(punctuation))\n",
    "    transformed_string = t.lower().translate(replace_punctuation)\n",
    "    response = tfidf.transform([transformed_string])\n",
    "    \n",
    "#     feature_names = tfidf.get_feature_names()\n",
    "#     for col in response.nonzero()[1]:\n",
    "#         print feature_names[col], ' - ', response[0, col]\n",
    "    \n",
    "#     print response.nonzero()[1]\n",
    "    if float(response.nonzero()[1].shape[0]) == 0:\n",
    "        return 0\n",
    "    return float(np.sum([response[0, col] for col in response.nonzero()[1]])) / float(response.nonzero()[1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getARI(string):\n",
    "    string = \" \".join(item.strip() for item in BeautifulSoup(string).find_all(text=True))\n",
    "    string = str(''.join([i if ord(i) < 128 else ' ' for i in string]))\n",
    "    s_count = float(len(nltk.sent_tokenize(string)))\n",
    "    w_count = float(len(nltk.wordpunct_tokenize(string)))\n",
    "    c_count = float(len(string))\n",
    "    \n",
    "    if s_count == 0:\n",
    "        return 12\n",
    "    \n",
    "    return math.ceil((4.71*(c_count/w_count)) + (0.5*(w_count/s_count)) - 21.43)\n",
    "\n",
    "\n",
    "\n",
    "def GetFeatures(data):\n",
    "    structured_data = []\n",
    "    index = 1\n",
    "    for d in data:\n",
    "        feat = []\n",
    "        if index % 10000 == 1:\n",
    "            print 'Starting', index\n",
    "            \n",
    "        feat.append(time.mktime(datetime.datetime.strptime(d[0]['created'], \"%Y-%m-%d %H:%M:%S\").timetuple()))\n",
    "        feat.append(getTransformedtfIdfScore(d[0]['description']))\n",
    "        feat.append(getARI(d[0]['description']))\n",
    "        structured_data.append(feat)\n",
    "        if index % 10000 == 1:\n",
    "            print 'Done', index\n",
    "        index += 1\n",
    "    \n",
    "    return structured_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1\n",
      "Done 1\n",
      "Starting 10001\n",
      "Done 10001\n",
      "Starting 20001\n",
      "Done 20001\n",
      "Starting 30001\n",
      "Done 30001\n",
      "Starting 40001\n",
      "Done 40001\n",
      "Starting 1\n",
      "Done 1\n",
      "Starting 10001\n",
      "Done 10001\n",
      "Starting 20001\n",
      "Done 20001\n",
      "Starting 30001\n",
      "Done 30001\n",
      "Starting 40001\n",
      "Done 40001\n",
      "Starting 50001\n",
      "Done 50001\n",
      "Starting 60001\n",
      "Done 60001\n",
      "Starting 70001\n",
      "Done 70001\n"
     ]
    }
   ],
   "source": [
    "new_data = GetFeatures(data)\n",
    "new_test_data = GetFeatures(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1466780064.0, 0.10791517320475999, 6.0]\n",
      "(49352, 3)\n",
      "[1465648181.0, 0.12883028455155554, 29.0]\n",
      "(74659, 3)\n"
     ]
    }
   ],
   "source": [
    "print new_data[0]\n",
    "print np.array(new_data).shape\n",
    "\n",
    "print new_test_data[0]\n",
    "print np.array(new_test_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('ut_tfidf_ari_train', new_data)\n",
    "np.save('ut_tfidf_ari_test', new_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
